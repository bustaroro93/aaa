{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877c9588-908c-468a-aac4-122a87dace7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "   PP_16 - MERGE ALL GOD FEATURES (GOD SOTA 2026)\n",
      "======================================================================\n",
      "   2025-12-17 11:31:47\n",
      "======================================================================\n",
      "\n",
      "[1/7] Finding latest SOTA file...\n",
      "  üìÇ Input: matches_ml_ready_SOTA_v5.parquet\n",
      "  üìÇ Output will be: SOTA_v6\n",
      "  Shape: (543527, 1325)\n",
      "\n",
      "[2/7] Merging opponent_adj features...\n",
      "  Loaded: (544245, 70)\n",
      "  ‚ö†Ô∏è  opponent_adj: 794 duplicate custom_match_id -> taking first\n",
      "  ‚úÖ opponent_adj: +69 columns, 16.3% coverage\n",
      "\n",
      "[3/7] Merging bradley_terry features...\n",
      "  Loaded: (544245, 19)\n",
      "  ‚ö†Ô∏è  bradley_terry: 794 duplicate custom_match_id -> taking first\n",
      "  ‚úÖ bradley_terry: +18 columns, 100.0% coverage\n",
      "\n",
      "[4/7] Merging travel features...\n",
      "  Loaded: (544245, 37)\n",
      "  ‚ö†Ô∏è  travel: 794 duplicate custom_match_id -> taking first\n",
      "  ‚úÖ travel: +36 columns, 100.0% coverage\n",
      "\n",
      "[5/7] Merging gnn features...\n",
      "  Loaded: (544245, 14)\n",
      "  ‚ö†Ô∏è  gnn: 794 duplicate custom_match_id -> taking first\n",
      "  ‚úÖ gnn: +13 columns, 100.0% coverage\n",
      "\n",
      "[6/7] Merging transformer features...\n",
      "  Loaded: (544245, 14)\n",
      "  ‚ö†Ô∏è  transformer: 794 duplicate custom_match_id -> taking first\n",
      "  ‚úÖ transformer: +13 columns, 100.0% coverage\n",
      "\n",
      "[7/7] Saving SOTA_v6...\n",
      "\n",
      "  ‚úÖ Saved: C:\\Users\\Administrateur\\Tennis POLAR v2\\data_clean\\ml_ready\\matches_ml_ready_SOTA_v6.parquet\n",
      "  Shape: (543527, 1474)\n",
      "  New columns: +149\n",
      "\n",
      "======================================================================\n",
      "   FEATURES SUMMARY BY SOURCE\n",
      "======================================================================\n",
      "  opponent_adj: 61 features\n",
      "  bradley_terry: 18 features\n",
      "  travel: 19 features\n",
      "  gnn: 12 features\n",
      "  transformer: 42 features\n",
      "\n",
      "======================================================================\n",
      "   ‚úÖ PP_16 MERGE COMPLETE! (24.9s)\n",
      "======================================================================\n",
      "\n",
      "üìã R√âSUM√â:\n",
      "   ‚Ä¢ Input: matches_ml_ready_SOTA_v5.parquet (1325 cols)\n",
      "   ‚Ä¢ Output: SOTA_v6 (1474 cols)\n",
      "   ‚Ä¢ Nouvelles features: +149\n",
      "\n",
      "üìã PROCHAINES √âTAPES:\n",
      "\n",
      "1. Ex√©cuter PP_17 (Feature Engineering)\n",
      "   ‚Üí Charge automatiquement SOTA_v6\n",
      "   ‚Üí Shuffle A/B + conversion winner/loser ‚Üí A/B\n",
      "   ‚Üí Feature selection + scaling\n",
      "\n",
      "2. Ex√©cuter PP_18 (Training GOD MODE)\n",
      "   ‚Üí TabNet + Neural Meta-Learner\n",
      "   ‚Üí Target AUC: 0.85+\n",
      "\n",
      "‚ö†Ô∏è  NOTE: Les features sont en format winner/loser.\n",
      "   PP_17 les convertira en A/B apr√®s le shuffle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# ===============================================\n",
    "# PP_16 - MERGE ALL GOD FEATURES (GOD SOTA 2026)\n",
    "# TennisTitan - Consolidation de toutes les features avanc√©es\n",
    "# ===============================================\n",
    "#\n",
    "# PIPELINE COMPLET:\n",
    "#   PP_08b (Opponent-Adjusted) ‚îÄ‚îê\n",
    "#   PP_12 (Bradley-Terry)      ‚îÄ‚îº‚îÄ‚îÄ‚Üí PP_16 (Merge) ‚Üí PP_17 ‚Üí PP_18\n",
    "#   PP_13 v2 (Travel+Surface)  ‚îÄ‚î§\n",
    "#   PP_14 (GNN)                ‚îÄ‚î§\n",
    "#   PP_15 (Transformer)        ‚îÄ‚îò\n",
    "#\n",
    "# Input: ml_ready/matches_ml_ready_SOTA_v5.parquet + features/*.parquet\n",
    "# Output: ml_ready/matches_ml_ready_SOTA_v6.parquet\n",
    "# ===============================================\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# ===============================================\n",
    "# CONFIGURATION\n",
    "# ===============================================\n",
    "ROOT = Path(r\"C:\\Users\\Administrateur\\Tennis POLAR v2\")\n",
    "DATA_CLEAN = ROOT / \"data_clean\"\n",
    "ML_READY = DATA_CLEAN / \"ml_ready\"\n",
    "FEATURES_DIR = DATA_CLEAN / \"features\"\n",
    "\n",
    "# Feature sources (ordre d'importance)\n",
    "FEATURE_SOURCES = {\n",
    "    # PP_08b - Opponent-Adjusted Stats\n",
    "    \"opponent_adj\": FEATURES_DIR / \"opponent_adjusted\" / \"opponent_adj_features.parquet\",\n",
    "    \n",
    "    # PP_12 - Bradley-Terry Ratings\n",
    "    \"bradley_terry\": FEATURES_DIR / \"bradley_terry\" / \"bt_features.parquet\",\n",
    "    \n",
    "    # PP_13 v2 - Travel + Surface Transition\n",
    "    \"travel\": FEATURES_DIR / \"travel_context\" / \"travel_features.parquet\",\n",
    "    \n",
    "    # PP_14 - GNN Player Embeddings\n",
    "    \"gnn\": FEATURES_DIR / \"player_embeddings\" / \"embedding_features.parquet\",\n",
    "    \n",
    "    # PP_15 - Sequence Transformer\n",
    "    \"transformer\": FEATURES_DIR / \"sequence_transformer\" / \"sequence_features.parquet\",\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"   PP_16 - MERGE ALL GOD FEATURES (GOD SOTA 2026)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"   {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# ===============================================\n",
    "# HELPER FUNCTIONS\n",
    "# ===============================================\n",
    "\n",
    "def find_latest_sota():\n",
    "    \"\"\"Find the latest SOTA version.\"\"\"\n",
    "    sota_files = list(ML_READY.glob(\"matches_ml_ready_SOTA_v*.parquet\"))\n",
    "    \n",
    "    if not sota_files:\n",
    "        base = ML_READY / \"matches_ml_ready.parquet\"\n",
    "        if base.exists():\n",
    "            return base, 1\n",
    "        raise FileNotFoundError(\"No SOTA file found!\")\n",
    "    \n",
    "    def get_version(p):\n",
    "        match = re.search(r'SOTA_v(\\d+)', p.stem)\n",
    "        return int(match.group(1)) if match else 0\n",
    "    \n",
    "    sota_files.sort(key=get_version, reverse=True)\n",
    "    latest = sota_files[0]\n",
    "    current_version = get_version(latest)\n",
    "    \n",
    "    return latest, current_version + 1\n",
    "\n",
    "\n",
    "def safe_join(df: pl.DataFrame, other: pl.DataFrame, on: list, name: str) -> pl.DataFrame:\n",
    "    \"\"\"Safe left join with logging and duplicate handling.\"\"\"\n",
    "    \n",
    "    if other is None:\n",
    "        print(f\"  ‚ö†Ô∏è  {name}: skipped (not found)\")\n",
    "        return df\n",
    "\n",
    "    # ‚úÖ AJOUTER ICI : Check duplicates\n",
    "    dup = other.select(pl.col(on[0]).is_duplicated().sum()).item()\n",
    "    if dup > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  {name}: {dup} duplicate {on[0]} -> taking first\")\n",
    "        other = other.unique(subset=on, keep=\"first\")\n",
    "        \n",
    "    before_cols = len(df.columns)\n",
    "    \n",
    "    # Get columns to add (excluding join keys)\n",
    "    new_cols = [c for c in other.columns if c not in on]\n",
    "    \n",
    "    # Check for duplicates and rename if needed\n",
    "    existing_cols = set(df.columns)\n",
    "    renamed_cols = {}\n",
    "    for col in new_cols:\n",
    "        if col in existing_cols:\n",
    "            renamed_cols[col] = f\"{col}_{name}\"\n",
    "            print(f\"      ‚ö†Ô∏è  Renamed {col} ‚Üí {col}_{name} (duplicate)\")\n",
    "    \n",
    "    if renamed_cols:\n",
    "        other = other.rename(renamed_cols)\n",
    "        new_cols = [renamed_cols.get(c, c) for c in new_cols]\n",
    "    \n",
    "    # Join\n",
    "    df = df.join(other, on=on, how=\"left\")\n",
    "    \n",
    "    # Calculate coverage\n",
    "    has_cols = [c for c in new_cols if c.lower().startswith(\"has_\")]\n",
    "    coverage_col = has_cols[0] if has_cols else (new_cols[0] if new_cols else None)\n",
    "    if coverage_col and coverage_col in df.columns:\n",
    "        non_null = df[coverage_col].is_not_null().sum()\n",
    "        coverage = non_null / df.shape[0] * 100\n",
    "        print(f\"  ‚úÖ {name}: +{len(new_cols)} columns, {coverage:.1f}% coverage\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ {name}: +{len(new_cols)} columns\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ===============================================\n",
    "# MAIN\n",
    "# ===============================================\n",
    "\n",
    "def main():\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    # =====================================\n",
    "    # LOAD BASE\n",
    "    # =====================================\n",
    "    print(\"\\n[1/7] Finding latest SOTA file...\")\n",
    "    \n",
    "    base_path, next_version = find_latest_sota()\n",
    "    \n",
    "    print(f\"  üìÇ Input: {base_path.name}\")\n",
    "    print(f\"  üìÇ Output will be: SOTA_v{next_version}\")\n",
    "    \n",
    "    df = pl.read_parquet(base_path)\n",
    "    initial_rows = len(df)\n",
    "    initial_cols = len(df.columns)\n",
    "    \n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    \n",
    "    # =====================================\n",
    "    # MERGE ALL FEATURE SOURCES\n",
    "    # =====================================\n",
    "    \n",
    "    step = 2\n",
    "    for name, path in FEATURE_SOURCES.items():\n",
    "        print(f\"\\n[{step}/7] Merging {name} features...\")\n",
    "        step += 1\n",
    "        \n",
    "        if path.exists():\n",
    "            try:\n",
    "                features = pl.read_parquet(path)\n",
    "                print(f\"  Loaded: {features.shape}\")\n",
    "                df = safe_join(df, features, [\"custom_match_id\"], name)\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error loading {path}: {e}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Not found: {path}\")\n",
    "    \n",
    "    # =====================================\n",
    "    # SAVE\n",
    "    # =====================================\n",
    "    print(f\"\\n[7/7] Saving SOTA_v{next_version}...\")\n",
    "    \n",
    "    output_path = ML_READY / f\"matches_ml_ready_SOTA_v{next_version}.parquet\"\n",
    "    df.write_parquet(output_path)\n",
    "    \n",
    "    elapsed = (datetime.now() - t0).total_seconds()\n",
    "    \n",
    "    # =====================================\n",
    "    # SUMMARY\n",
    "    # =====================================\n",
    "    final_cols = len(df.columns)\n",
    "    new_cols = final_cols - initial_cols\n",
    "    \n",
    "    print(f\"\\n  ‚úÖ Saved: {output_path}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  New columns: +{new_cols}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"   FEATURES SUMMARY BY SOURCE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Count features by prefix\n",
    "    feature_groups = {\n",
    "        \"opponent_adj\": [\"win_rate_vs_\", \"ace_rate_vs_\", \"hold_rate_vs_\", \"bp_conv_vs_\", \"adj_dominance\"],\n",
    "        \"bradley_terry\": [\"bt_\"],\n",
    "        \"travel\": [\"travel_\", \"timezone_\", \"home_\", \"altitude\", \"surface_transition\", \"surface_adaptation\"],\n",
    "        \"gnn\": [\"emb_\"],\n",
    "        \"transformer\": [\"seq_\"],\n",
    "    }\n",
    "    \n",
    "    for source, prefixes in feature_groups.items():\n",
    "        cols = []\n",
    "        for prefix in prefixes:\n",
    "            cols.extend([c for c in df.columns if prefix in c.lower()])\n",
    "        cols = list(set(cols))\n",
    "        if cols:\n",
    "            print(f\"  {source}: {len(cols)} features\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"   ‚úÖ PP_16 MERGE COMPLETE! ({elapsed:.1f}s)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\"\"\n",
    "üìã R√âSUM√â:\n",
    "   ‚Ä¢ Input: {base_path.name} ({initial_cols} cols)\n",
    "   ‚Ä¢ Output: SOTA_v{next_version} ({final_cols} cols)\n",
    "   ‚Ä¢ Nouvelles features: +{new_cols}\n",
    "\n",
    "üìã PROCHAINES √âTAPES:\n",
    "\n",
    "1. Ex√©cuter PP_17 (Feature Engineering)\n",
    "   ‚Üí Charge automatiquement SOTA_v{next_version}\n",
    "   ‚Üí Shuffle A/B + conversion winner/loser ‚Üí A/B\n",
    "   ‚Üí Feature selection + scaling\n",
    "\n",
    "2. Ex√©cuter PP_18 (Training GOD MODE)\n",
    "   ‚Üí TabNet + Neural Meta-Learner\n",
    "   ‚Üí Target AUC: 0.85+\n",
    "\n",
    "‚ö†Ô∏è  NOTE: Les features sont en format winner/loser.\n",
    "   PP_17 les convertira en A/B apr√®s le shuffle.\n",
    "\"\"\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59e5a0-862e-47a8-a3ce-490ce5a27da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
